{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d67d2e9c-ab8f-4fee-99dc-08491a71991c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anneezurike/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from flask import Flask, request, jsonify, json\n",
    "from skill_edu import education_keywords, skill_dataset\n",
    "from datetime import datetime\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Load pre-trained BERT model for embeddings\n",
    "bert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "01af2576-0a97-4caa-8101-37b3284cf2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Extracts text from a PDF resume (given a PDF file object) and cleans it.\"\"\"\n",
    "    if isinstance(pdf_file, str):  # If the input is a file path, open the file\n",
    "        with open(pdf_file, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \" \".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "            text = text.lower()\n",
    "    else:  # If the input is already a file object (PdfFileReader accepts file-like objects)\n",
    "        reader = PyPDF2.PdfReader(pdf_file)\n",
    "        text = \" \".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "        text = text.lower()\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed4a376e-0cc6-4d8c-9b7a-16a5757d92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Check if the text is valid and non-empty\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return \"\"  # or return some default text\n",
    "    \"\"\"Cleans the extracted text by removing special characters, numbers, and stopwords.\"\"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13aa3d43-9e42-4db0-bc2a-2c9672d1ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sensitive_info(text):\n",
    "    \"\"\"Removes potential bias-related words from resume text.\"\"\"\n",
    "    bias_keywords = [\"male\", \"female\", \"black\", \"white\", \"asian\", \"hispanic\", \"married\", \"single\"]\n",
    "    for word in bias_keywords:\n",
    "        text = text.replace(word, \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063a1c38-e420-4b2c-a59e-b4eec20141ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_skills(skills_a, skills_b):\n",
    "    if isinstance(skills_b, str):\n",
    "        skills_b = [item.strip() for item in skills_b.split(\", \")]\n",
    "    skills = {skill for skill in skills_a if skill in skills_b}\n",
    "    return skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c6e875-a951-4e22-86e6-dd9b25f1dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    \"\"\"Efficiently extracts skills, education, and experience from resume text.\"\"\"\n",
    "    extracted_info = {\"Skills\": set(), \"Education\": set(), \"Experience\": set()}\n",
    "    # Regex patterns to capture different ways experience is written\n",
    "    experience_patterns = [\n",
    "        # r'(\\d+)\\s*(?:\\+|-)?\\s*(?:years?|yrs?)\\s*(?:of|in|working in|as)?\\s*experience',\n",
    "        r'(\\d+\\s*[+-]?\\s*(?:years?|yrs?))',\n",
    "        r'(\\d+)\\s*(?:to|-) (\\d+)\\s*years',  # e.g., \"3 to 5 years\"\n",
    "        r'(\\d+)-(\\d+)\\s*years'  # e.g., \"3-5 years\"\n",
    "    ]\n",
    "\n",
    "    # Convert text to lowercase for case-insensitive matching\n",
    "    text = text.lower()\n",
    "    skill_data = list(map(str.lower, skill_dataset))\n",
    "    education_data = list(map(str.lower, education_keywords))\n",
    "\n",
    "    # Regex-based experience extraction\n",
    "    # Extract matches using regex\n",
    "    for pattern in experience_patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                if isinstance(match, tuple):  # Handles cases like \"3-5 years\"\n",
    "                    extracted_info[\"Experience\"].add(f\"{match[0]}-{match[1]} years\")\n",
    "                else:\n",
    "                    extracted_info[\"Experience\"].add(f\"{match} years\")\n",
    "\n",
    "    text = clean_text(text)\n",
    "\n",
    "    # Fast skill matching using set intersection\n",
    "    extracted_info[\"Skills\"] = {skill for skill in skill_data if skill in text}\n",
    "\n",
    "    # Fast education matching\n",
    "    extracted_info[\"Education\"] = {edu for edu in education_data if edu in text}\n",
    "\n",
    "    return {\n",
    "        \"skills\": list(extracted_info[\"Skills\"]),\n",
    "        \"education\": list(extracted_info[\"Education\"]),\n",
    "        \"experience\": list(extracted_info[\"Experience\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a47b5a6-b3f4-4154-a462-d8b1e6e11b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0091bace-5f4a-4b02-bbc3-50285c93af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(text1, text2):\n",
    "    \"\"\"Compute cosine similarity between two text embeddings.\"\"\"\n",
    "    embedding1 = bert_model.encode(text1).reshape(1, -1)\n",
    "    embedding2 = bert_model.encode(text2).reshape(1, -1)\n",
    "    return cosine_similarity(embedding1, embedding2)[0][0]\n",
    "\n",
    "def get_resume_ranking_score(ranking_data, job_data):\n",
    "    \"\"\"Provides a detailed breakdown of resume scoring.\"\"\"\n",
    "    \n",
    "    # Compute similarity scores for different sections\n",
    "    general_score = compute_similarity(ranking_data[\"resume_text\"], job_data[\"description\"]) * 15  # 15% weight\n",
    "    skills_score = compute_similarity(ranking_data[\"r_skills\"], job_data[\"skills\"]) * 40  # 40% weight\n",
    "    experience_similarity = compute_similarity(ranking_data[\"resume_text\"], job_data[\"experience\"])  \n",
    "    experience_score = compute_experience_score(ranking_data[\"experience\"], job_data[\"experience\"], experience_similarity) * 30  # 30% weight\n",
    "    education_score = compute_similarity(ranking_data[\"education\"], job_data[\"education\"]) * 15  # 15% weight\n",
    "    \n",
    "\n",
    "    # Calculate total score\n",
    "    total_score = skills_score + experience_score + education_score + general_score\n",
    "\n",
    "    # Return breakdown\n",
    "    return {\n",
    "        \"ts\": round(total_score, 2),\n",
    "        \"ss\": round(skills_score, 2),\n",
    "        \"ex\": round(experience_similarity, 2),\n",
    "        \"ed\": round(education_score, 2),\n",
    "        \"ge\": round(general_score, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41140f9e-c885-44ee-b8f9-94973430f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_exp(text):\n",
    "    # Find the first match\n",
    "    for pattern in rank_exp_pattern:\n",
    "        matches = re.findall(pattern, text)\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                result = f\"{match} years\"\n",
    "    return result or \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcce6e7e-8c9d-4ed6-935a-423ca14e573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experience(text):\n",
    "    \"\"\"Extracts numerical years of experience from explicit mentions or date ranges, including month-name formats.\"\"\"\n",
    "    \n",
    "    # Explicit experience extraction (e.g., \"5 years of experience\")\n",
    "    explicit_match = re.findall(r'(\\d+)\\s*(?:\\+|-)?\\s*years?', text)\n",
    "    \n",
    "    if explicit_match:\n",
    "        return max(map(int, explicit_match))  # Take the highest number found\n",
    "    \n",
    "    # Patterns for different date formats\n",
    "    date_patterns = [\n",
    "        r'(\\b\\d{4}\\b)\\s*[-to]+\\s*(\\b\\d{4}\\b)',  # \"2015 - 2020\" / \"2015 to 2020\"\n",
    "        r'(\\d{2}/\\d{4})\\s*[-â€“to]+\\s*(\\d{2}/\\d{2}/\\d{4}|\\d{2}/\\d{4})',  # \"05/2020 - 09/2024\"\n",
    "        r'(\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec|January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4})\\s*[-to]+\\s*(\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec|January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4})'\n",
    "        # Handles: \"March 2016 - June 2018\"\n",
    "    ]\n",
    "    \n",
    "    years = []\n",
    "\n",
    "    for pattern in date_patterns:\n",
    "        matches = re.findall(pattern, text, flags=re.IGNORECASE)\n",
    "        for start, end in matches:\n",
    "            try:\n",
    "                # Extract year from different formats\n",
    "                start_year = int(re.search(r'\\d{4}', start).group())\n",
    "                end_year = int(re.search(r'\\d{4}', end).group())\n",
    "                \n",
    "                if start_year <= end_year:\n",
    "                    years.append((start_year, end_year))\n",
    "            except (ValueError, AttributeError):\n",
    "                continue\n",
    "\n",
    "    if not years:\n",
    "        return 0, None, None  # No valid years found\n",
    "\n",
    "    # Step 1: Sort year ranges by start year\n",
    "    years.sort()\n",
    "    \n",
    "    # Step 2: Merge overlapping or consecutive time periods\n",
    "    merged_ranges = []\n",
    "    current_start, current_end = years[0]\n",
    "\n",
    "    for start, end in years[1:]:\n",
    "        if start <= current_end:  # Overlapping or consecutive\n",
    "            current_end = max(current_end, end)  # Extend the range\n",
    "        else:\n",
    "            merged_ranges.append((current_start, current_end))  # Store the merged period\n",
    "            current_start, current_end = start, end\n",
    "\n",
    "    merged_ranges.append((current_start, current_end))  # Add last range\n",
    "\n",
    "    # Step 3: Calculate total experience\n",
    "    total_experience = sum(end - start for start, end in merged_ranges)\n",
    "    min_year = min(start for start, _ in merged_ranges)\n",
    "    max_year = max(end for _, end in merged_ranges)\n",
    "\n",
    "    return total_experience, min_year, max_year\n",
    "    # return years if years else 0  # Return inferred experience or 0 if nothing found\n",
    "\n",
    "\n",
    "def compute_experience_score(resume_exp, job_exp, similarity_score):\n",
    "    \"\"\"Computes the final experience score combining numerical experience and text similarity.\"\"\"\n",
    "    resume_years = extract_experience(resume_exp)\n",
    "    job_years = extract_experience(job_exp)\n",
    "\n",
    "    if job_years == 0:  # No required experience specified\n",
    "        num_experience_score = 1.0  # Full score if no experience requirement\n",
    "    else:\n",
    "        num_experience_score = min(resume_years / job_years, 1.5)  # Cap scaling at 1.5 to avoid over-rewarding\n",
    "\n",
    "    # Multiply structured experience score with text similarity score to balance both\n",
    "    final_experience_score = num_experience_score * similarity_score  \n",
    "\n",
    "    return final_experience_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "67b38280-a61c-45d0-8545-57f95d6900d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2016, 2024)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_experience_years(text):\n",
    "    \"\"\"Extracts and computes total non-overlapping years of experience, removing education years.\"\"\"\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Identify positions of 'education' and 'work' in the text\n",
    "    edu_index = text_lower.find(\"education\")\n",
    "    work_index = text_lower.find(\"work\")  # Could be 'work experience', 'work history', etc.\n",
    "\n",
    "    if edu_index != -1:\n",
    "        if work_index != -1 and work_index > edu_index:\n",
    "            # If 'work' is found AFTER 'education', extract the text between them\n",
    "            education_text = text[edu_index:work_index]\n",
    "        else:\n",
    "            # If 'work' is not found, take everything from 'education' to the last occurrence of a year\n",
    "            match = re.findall(r'\\b\\d{4}\\b', text)\n",
    "            if match:\n",
    "                last_year_index = text.rfind(match[-1])  # Find last occurrence of a year\n",
    "                education_text = text[edu_index:last_year_index + 4]  # +4 to include the last year\n",
    "            else:\n",
    "                education_text = text[edu_index:]  # If no years, take everything from 'education' onward\n",
    "    else:\n",
    "        education_text = \"\"  # No education section found\n",
    "\n",
    "    # Patterns to extract year ranges (e.g., \"2015 - 2020\", \"05/2020 - 09/2024\", \"March 2016 - June 2018\")\n",
    "    patterns = [\n",
    "        r'(\\b\\d{4}\\b)\\s*[-to]+\\s*(\\b\\d{4}\\b)',  # Matches '2015 - 2020' or '2015 to 2020'\n",
    "        r'(\\d{2}/\\d{4})\\s*[-â€“to]+\\s*(\\d{2}/\\d{2}/\\d{4}|\\d{2}/\\d{4})',  # Matches '05/2020 - 09/2024'\n",
    "        r'(\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec|January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4})\\s*[-to]+\\s*(\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec|January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4})'  # Matches 'March 2016 - June 2018'\n",
    "    ]\n",
    "\n",
    "    years = []\n",
    "    all_years = set()  # To store all extracted years\n",
    "    edu_years = set()  # To store years found in the education section\n",
    "\n",
    "    for pattern in patterns:\n",
    "        for match in re.findall(pattern, text):\n",
    "            try:\n",
    "                if len(match) == 2:  # Matching year ranges like '2015 - 2020'\n",
    "                    start_year, end_year = map(int, match)\n",
    "                    if start_year <= end_year:\n",
    "                        years.append((start_year, end_year))\n",
    "                        all_years.add(start_year)\n",
    "                        all_years.add(end_year)\n",
    "                elif len(match) == 1:  # Matching month/year or month-day/year\n",
    "                    # In case of month/year or month-day/year, handle these formats differently\n",
    "                    # For example, \"05/2020 - 09/2024\" or \"March 2016 - June 2018\"\n",
    "                    # The extracted range can be converted into year-based range if necessary\n",
    "                    pass\n",
    "            except ValueError:\n",
    "                continue  # Ignore invalid matches\n",
    "\n",
    "    # Extract years from the education section\n",
    "    for pattern in patterns:\n",
    "        for match in re.findall(pattern, education_text):\n",
    "            try:\n",
    "                if len(match) == 2:  # Matching year ranges like '2015 - 2020'\n",
    "                    start_year, end_year = map(int, match)\n",
    "                    if start_year <= end_year:\n",
    "                        edu_years.add(start_year)\n",
    "                        edu_years.add(end_year)\n",
    "                elif len(match) == 1:  # Matching month/year or month-day/year\n",
    "                    # Handle month-based or month-day-based formats in the education section if needed\n",
    "                    pass\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Remove education years from the extracted work experience years\n",
    "    years = [(start, end) for start, end in years if start not in edu_years and end not in edu_years]\n",
    "\n",
    "    if not years:\n",
    "        return 0, None, None  # No valid work experience years found\n",
    "\n",
    "    # Step 1: Sort year ranges by start year\n",
    "    years.sort()\n",
    "    \n",
    "    # Step 2: Merge overlapping or consecutive time periods\n",
    "    merged_ranges = []\n",
    "    current_start, current_end = years[0]\n",
    "\n",
    "    for start, end in years[1:]:\n",
    "        if start <= current_end:  # Overlapping or consecutive\n",
    "            current_end = max(current_end, end)\n",
    "        else:\n",
    "            merged_ranges.append((current_start, current_end))\n",
    "            current_start, current_end = start, end\n",
    "\n",
    "    merged_ranges.append((current_start, current_end))\n",
    "\n",
    "    # Step 3: Calculate total experience\n",
    "    total_experience = sum(end - start for start, end in merged_ranges)\n",
    "    min_year = min(start for start, _ in merged_ranges)\n",
    "    max_year = max(end for _, end in merged_ranges)\n",
    "\n",
    "    return total_experience, min_year, max_year\n",
    "\n",
    "# Example test case\n",
    "resume_text = \"\"\"\n",
    "Work Experience:\n",
    "Software Engineer at DEF Inc, 2016 - 2019.\n",
    "Senior Developer at GHI Tech, 2019 - 2024.\n",
    "\n",
    "Education:\n",
    "Bachelor of Science in Computer Science, XYZ University, 2008 - 2012.\n",
    "Master's in Data Science, ABC Institute, 2012 - 2015.\n",
    "\"\"\"\n",
    "\n",
    "print(extract_experience_years(resume_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "5526d09b-57a1-46d8-b97b-b6ffd88b4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_education(text):\n",
    "    text = fix_broken_words(text)\n",
    "    \n",
    "    edu_index = text.find(\"education\") \n",
    "    work_index = re.search(r'work|experience', text[edu_index:])\n",
    "\n",
    "    if edu_index != -1:\n",
    "        if work_index != '':\n",
    "            real_work_index = edu_index + work_index.start()\n",
    "            return text[edu_index:real_work_index]\n",
    "        else:\n",
    "            # If 'work' is not found, take everything from 'education' to the last occurrence of a year\n",
    "            matches = list(re.finditer(r'education', text))\n",
    "    \n",
    "            if matches:\n",
    "                last_edu_index = matches[-1]  # Get the last occurrence (bottom-most)\n",
    "                last_edu_index = last_edu_index.start()\n",
    "                if edu_index != last_edu_index:\n",
    "                    return text[last_edu_index:]\n",
    "                else:\n",
    "                    return text[edu_index:]\n",
    "    else:\n",
    "        education_text = \"\"  # No education section found\n",
    "\n",
    "    return education_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "30e41dfe-529c-4bb6-aefa-56ef7fccd94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years(text):\n",
    "    # Get current year\n",
    "    current_year = datetime.now().year\n",
    "\n",
    "    # Patterns to extract year ranges\n",
    "    patterns = [\n",
    "        r'(\\b\\d{4}\\b)\\s*[-to]+\\s*(\\b\\d{4}\\b|\\bcurrent\\b|\\bpresent\\b)',  # Handles \"2015 - 2020\" and \"2015 - current\"\n",
    "        r'(\\d{2}/\\d{4})\\s*[-â€“to]+\\s*(\\d{2}/\\d{2}/\\d{4}|\\d{2}/\\d{4}|\\bcurrent\\b|\\bpresent\\b)',  # Handles \"05/2020 - current\"\n",
    "        r'(\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec|January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4})\\s*[-to]+\\s*(\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec|January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4}|\\bcurrent\\b|\\bpresent\\b)'  # Handles \"March 2016 - current\"\n",
    "    ]\n",
    "\n",
    "    years = []\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text, flags=re.IGNORECASE)\n",
    "        for start, end in matches:\n",
    "            try:\n",
    "                start_year = int(re.search(r'\\d{4}', start).group())\n",
    "                \n",
    "                # If end year is \"current\" or \"present\", use current year\n",
    "                if re.search(r'current|present', end, flags=re.IGNORECASE):\n",
    "                    end_year = current_year\n",
    "                else:\n",
    "                    end_year = int(re.search(r'\\d{4}', end).group())\n",
    "\n",
    "                if start_year <= end_year:\n",
    "                    years.append((start_year, end_year))\n",
    "            except (ValueError, AttributeError):\n",
    "                continue  # Skip if parsing fails\n",
    "\n",
    "    return years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "97b80ed2-c6cb-4748-874e-f73b516f613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_broken_words(text):\n",
    "    \"\"\"\n",
    "    Fixes broken words by merging improperly split words.\n",
    "    Also removes extra spaces.\n",
    "    \"\"\"\n",
    "    # Fix cases like \"w ork\" -> \"work\", \"wo rk\" -> \"work\"\n",
    "    text = re.sub(r'(\\w)(?=\\s{1,2}\\w)', r'\\1', text)   # Merges short split words\n",
    "\n",
    "    # Remove extra whitespace everywhere\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Step 2: Fix broken words (merge improperly split words)\n",
    "    text = re.sub(r'(\\b\\w{1,10})\\s(?=\\w{1,10}\\b)', r'\\1', text)\n",
    "\n",
    "    # Add space between a letter and a number (e.g., \"september2011\" -> \"september 2011\")\n",
    "    text = re.sub(r'([a-zA-Z])(\\d)', r'\\1 \\2', text)\n",
    "\n",
    "    # Add space between a number and a letter (e.g., \"2011newbrunswick\" -> \"2011 newbrunswick\")\n",
    "    text = re.sub(r'(\\d)([a-zA-Z])', r'\\1 \\2', text)\n",
    "\n",
    "    # Add space before any month name (e.g., \"newbrunswickseptember\" -> \"newbrunswick september\")\n",
    "    months = r\"(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec|\" \\\n",
    "             r\"January|February|March|April|May|June|July|August|September|\" \\\n",
    "             r\"October|November|December)\"\n",
    "    text = re.sub(r'(\\w)(' + months + r')', r'\\1 \\2', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Add space between a lowercase letter and an uppercase letter\n",
    "    # text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "308f7f78-574e-49c9-928a-32e62149e06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2015, 2025), (2008, 2012), (2015, 2025), (2012, 2015), (2011, 2012)] [(2008, 2012)] [(2015, 2025), (2015, 2025), (2012, 2015), (2011, 2012)]\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "file = \"./../../applicants_resumes/resume 3.pdf\"\n",
    "# job_data['description'] = \"Our client is looking for a PHP Symfony Developer who impresses with 5 years experience in the backend development of websites and applications as well as with APIs. Good knowledge of PHP (Symfony) and MySQL as well as object-oriented programming and an understanding of database and caching systems such as MySQL, Redis and ElasticSearch are an advantage. experience in software design techniques, test-driven development and distributed architecture. excellent communication skills. Fluent written and spoken German or English\"\n",
    "                                        \n",
    "job_data = {\n",
    "    \"description\": \"Our client is looking for a PHP Symfony Developer who impresses with Practical  experience in the backend development of websites and applications as well as with APIs. Good knowledge of PHP (Symfony) and MySQL as well as object-oriented programming and an understanding of database and caching systems such as MySQL, Redis and ElasticSearch are an advantage. experience in software design techniques, test-driven development and distributed architecture. excellent communication skills. Fluent written and spoken German or English\",\n",
    "    \"skills\": \"php, symfony, mysql, design patterns, clean code, html, git\",\n",
    "    \"experience\": \"Software Developer with 5 years experience in web development\",\n",
    "    \"education\": \"Computer Science bsc required\"\n",
    "}\n",
    "# Apply clean_text to each value in job_example\n",
    "# job_data = {key: clean_text(value) for key, value in job_data.items()}\n",
    "\n",
    "resume_text = extract_text_from_pdf(file)\n",
    "        \n",
    "# similarity_score = get_resume_ranking_score(resume_text, job_data['description'])\n",
    "ranking_data = extract_entities(resume_text)\n",
    "ranking_data['r_skills'] = filter_skills(ranking_data['skills'], job_data['skills'])\n",
    "ranking_data[\"resume_text\"] = remove_sensitive_info(clean_text(resume_text)) # remove bias \n",
    "# ranking_data[\"score\"] = round(similarity_score, 2)\n",
    "\n",
    "# scores = get_resume_ranking_score(ranking_data, job_data)\n",
    "# Drop the key 'resume_text'\n",
    "del ranking_data['resume_text']\n",
    "# result = ranking_data | scores\n",
    "\n",
    "# print(f\"ðŸ”¹ **Real Resume Ranking Score:** {resume_score:.4f}\")\n",
    "# Remove extra spaces between letters in words\n",
    "resume_text = re.sub(r'(?<=\\b\\w) (?=\\w\\b)', '', resume_text)\n",
    "\n",
    "# Remove extra whitespace everywhere\n",
    "resume_text = re.sub(r'\\s+', ' ', resume_text).strip()\n",
    "\n",
    "edu_text = get_education(resume_text)\n",
    "education_years = get_years(edu_text)\n",
    "years_range = get_years(resume_text)\n",
    "# Remove education years from work experience years\n",
    "filtered_years = [years for years in years_range if years not in education_years]\n",
    "\n",
    "print(years_range, education_years, filtered_years)\n",
    "# print(education_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1896e19f-d34b-49fa-bc0f-95df67d05dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['php', 'symfony', 'mysql', 'design patterns', 'clean code', 'html', 'git']\n"
     ]
    }
   ],
   "source": [
    "skill = \"php, symfony, mysql, design patterns, clean code, html, git\"\n",
    "skill_dataset = skill.split(\", \")\n",
    "\n",
    "# print(f\"ðŸ”¹ **Real Resume Ranking Score:** {resume_score:.4f}\")\n",
    "print(skill_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120152a8-009f-4dbc-a457-c4eafb7152da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb0213-c418-49b1-9565-4895f25088cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume ranking based on job description\n",
    "def rank_resumes(job_description, top_n=5):\n",
    "    job_description_cleaned = clean_text(job_description)\n",
    "    job_vector = vectorizer.transform([job_description_cleaned])\n",
    "    \n",
    "    # Use Nearest Neighbors to find similar resumes\n",
    "    nn = NearestNeighbors(n_neighbors=top_n, metric='cosine')\n",
    "    nn.fit(X)\n",
    "    distances, indices = nn.kneighbors(job_vector)\n",
    "    \n",
    "    return df.iloc[indices[0]]\n",
    "\n",
    "# Example usage\n",
    "job_desc = \"Looking for a data scientist with expertise in Python and machine learning.\"\n",
    "top_resumes = rank_resumes(job_desc, top_n=5)\n",
    "print(top_resumes[['category', 'resume_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409823b-8a10-406d-8d82-02574a6fb4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032fce66-bca2-4ca8-afae-e1b8f7711ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "43e7e04f-2fd5-4f22-9ca7-d18ca4ef3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final step above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92647db5-291a-407f-9397-237416da3f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5deb9f7-0510-403b-9175-58a916bbe063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
