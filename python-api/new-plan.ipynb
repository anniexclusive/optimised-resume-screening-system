{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d67d2e9c-ab8f-4fee-99dc-08491a71991c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anneezurike/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "import spacy  # NLP library for text processing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from difflib import get_close_matches\n",
    "import spacy\n",
    "from skill_edu import education_keywords, skill_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load a pre-trained NER model (e.g., spaCy's model)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ccc3b-ff95-45bd-bd99-f45e0d1ecb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01af2576-0a97-4caa-8101-37b3284cf2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Extracts text from a PDF resume (given a PDF file object) and cleans it.\"\"\"\n",
    "    if isinstance(pdf_file, str):  # If the input is a file path\n",
    "        with open(pdf_file, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \" \".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "    else:  # If the input is already a file object \n",
    "        reader = PyPDF2.PdfReader(pdf_file)\n",
    "        text = \" \".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "\n",
    "    return clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed4a376e-0cc6-4d8c-9b7a-16a5757d92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Check if the text is valid and non-empty\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return \"\"  # or return some default text\n",
    "    \"\"\"Cleans the extracted text by removing special characters, numbers, and stopwords.\"\"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b474910e-2b5a-4608-a914-d221b88d766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text_array):\n",
    "    if text_array:\n",
    "        lowercase_array = list(map(str.lower, text_array))\n",
    "        return lowercase_array\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13aa3d43-9e42-4db0-bc2a-2c9672d1ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sensitive_info(text):\n",
    "    \"\"\"Removes potential bias-related words from resume text.\"\"\"\n",
    "    bias_keywords = [\"male\", \"female\", \"black\", \"white\", \"asian\", \"hispanic\", \"married\", \"single\"]\n",
    "    for word in bias_keywords:\n",
    "        text = text.replace(word, \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85c6e875-a951-4e22-86e6-dd9b25f1dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_patterns = [\n",
    "        r\"(\\d+)\\s*(?:\\+|-)?\\s*(?:years?|yrs?)\\s*(?:of)?\\s*experience\",  # e.g., \"5 years of experience\"\n",
    "        r'(\\d+)\\s*(?:\\+|-)?\\s*(?:years?|yrs?)\\s*(?:in|working in|as)',  # e.g., \"3+ years in software development\"\n",
    "        r'(\\d+)-(\\d+)\\s*years'  # e.g., \"3-5 years experience\"\n",
    "    ]\n",
    "\n",
    "def extract_entities(text):\n",
    "    \"\"\"Efficiently extracts skills, education, and experience from resume text.\"\"\"\n",
    "    extracted_info = {\"Skills\": set(), \"Education\": set(), \"Experience\": set()}\n",
    "\n",
    "    # Convert text to lowercase for case-insensitive matching\n",
    "    text = text.lower()\n",
    "    skill_data = to_lower(skill_dataset)\n",
    "    education_data = to_lower(education_keywords)\n",
    "\n",
    "    # Fast skill matching using set intersection\n",
    "    extracted_info[\"Skills\"] = {skill for skill in skill_data if skill in text}\n",
    "\n",
    "    # Fast education matching\n",
    "    extracted_info[\"Education\"] = {edu for edu in education_data if edu in text}\n",
    "\n",
    "    # Regex-based experience extraction\n",
    "    for pattern in experience_patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                if isinstance(match, tuple):  # Handles cases like \"3-5 years\"\n",
    "                    extracted_info[\"Experience\"].add(f\"{match[0]}-{match[1]} years\")\n",
    "                else:\n",
    "                    extracted_info[\"Experience\"].add(f\"{match} years\")\n",
    "\n",
    "    return {\n",
    "        \"Skills\": list(extracted_info[\"Skills\"]),\n",
    "        \"Education\": list(extracted_info[\"Education\"]),\n",
    "        \"Experience\": list(extracted_info[\"Experience\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a28341-1111-471a-933d-5003d461a6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a47b5a6-b3f4-4154-a462-d8b1e6e11b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n",
      "{'Skills': ['data visualization', 'symfony', 'graphql', 'php', 'html', 'seo', 'git', 'sem', 'restful apis', 'docker', 'java', 'javascript', 'laravel', 'python', 'web development', 'css', 'mysql', 'sql'], 'Education': ['software engineering', 'computer science', 'history', 'bsc', 'web development', 'education', 'management'], 'Experience': ['8 years']}\n"
     ]
    }
   ],
   "source": [
    "resume = extract_text_from_pdf('./applicants_resumes/EZURIKE ANNE_CHIBUZO_CV.pdf')\n",
    "print(extract_entities(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23f8ea41-3383-4028-bc62-9f271ea91d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model for embeddings\n",
    "bert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6f55b3f-016a-4948-bc33-467ce9c9638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resume_ranking_score(resume_text, job_description):\n",
    "    \"\"\"Ranks resumes using BERT embeddings and cosine similarity.\"\"\"\n",
    "    # Extract and clean resume text\n",
    "    cleaned_resume = remove_sensitive_info(resume_text) # remove bias\n",
    "\n",
    "    # Encode the resume and job description\n",
    "    resume_embedding = bert_model.encode(cleaned_resume)\n",
    "    job_embedding = bert_model.encode(job_description)\n",
    "\n",
    "    # Compute similarity score\n",
    "    similarity_score = cosine_similarity([resume_embedding], [job_embedding])[0][0]\n",
    "    \n",
    "    return float(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "308f7f78-574e-49c9-928a-32e62149e06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… **Real Resume Similarity Score:** 0.5963\n",
      "ðŸ”¹ **Real Resume Ranking Score:** 0.5963\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "real_resume_path = \"./applicants_resumes/EZURIKE ANNE_CHIBUZO_CV.pdf\"\n",
    "job_desc = \"Our client is looking for a PHP Symfony Developer who impresses with Practical  experience in the backend development of websites and applications as well as with APIs. Good knowledge of PHP (Symfony) and MySQL as well as object-oriented programming and an understanding of database and caching systems such as MySQL, Redis and ElasticSearch are an advantage. experience in software design techniques, test-driven development and distributed architecture. excellent communication skills. Fluent written and spoken German or English\"\n",
    "\n",
    "resume_score = get_resume_ranking_score(real_resume_path, job_desc)\n",
    "print(f\"ðŸ”¹ **Real Resume Ranking Score:** {resume_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896e19f-d34b-49fa-bc0f-95df67d05dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120152a8-009f-4dbc-a457-c4eafb7152da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb0213-c418-49b1-9565-4895f25088cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume ranking based on job description\n",
    "def rank_resumes(job_description, top_n=5):\n",
    "    job_description_cleaned = clean_text(job_description)\n",
    "    job_vector = vectorizer.transform([job_description_cleaned])\n",
    "    \n",
    "    # Use Nearest Neighbors to find similar resumes\n",
    "    nn = NearestNeighbors(n_neighbors=top_n, metric='cosine')\n",
    "    nn.fit(X)\n",
    "    distances, indices = nn.kneighbors(job_vector)\n",
    "    \n",
    "    return df.iloc[indices[0]]\n",
    "\n",
    "# Example usage\n",
    "job_desc = \"Looking for a data scientist with expertise in Python and machine learning.\"\n",
    "top_resumes = rank_resumes(job_desc, top_n=5)\n",
    "print(top_resumes[['category', 'resume_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409823b-8a10-406d-8d82-02574a6fb4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032fce66-bca2-4ca8-afae-e1b8f7711ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "43e7e04f-2fd5-4f22-9ca7-d18ca4ef3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final step above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92647db5-291a-407f-9397-237416da3f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5deb9f7-0510-403b-9175-58a916bbe063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
